{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: When running the first cell you will be prompted to pick your Python environment, for the pre-built container choose:\n",
    " * **Python Environment** on the first dropdown\n",
    " * **Python 3.10.x** on the second dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login --use-device-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIClient: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class WorkspaceHubOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.generative import AIClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# connects to project defined in the config.json file at the root of the repo\n",
    "# use \"ai init\" to update this to point at your project\n",
    "client = AIClient.from_config(DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Azure OpenAI and Cognitive Services Connections and Set in Environment   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class WorkspaceConnection: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "# Log into the Azure CLI (run az login --use-device code) before running this step!\n",
    "default_aoai_connection = client.get_default_aoai_connection()\n",
    "default_aoai_connection.set_current_environment()\n",
    "\n",
    "# change this if you use different connection name\n",
    "default_acs_connection = client.connections.get(\"Default_CognitiveSearch\")\n",
    "default_acs_connection.set_current_environment()\n",
    "\n",
    "# change these if you use different deployment names\n",
    "# if you do that, also update the deployment name in qna_simple/langchain_model.py \n",
    "chat_model_deployment = \"gpt-35-turbo-16k-0613\"\n",
    "embedding_model_deployment = \"text-ada-embedding-002-2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build MLIndex Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.generative.operations._index_data_source import LocalSource, ACSOutputConfig\n",
    "from azure.ai.generative.functions.build_mlindex import build_mlindex\n",
    "\n",
    "# build the index using the product catalog docs from data/3-product-info\n",
    "index = build_mlindex(\n",
    "    output_index_name=\"product-info-cog-search-index\",\n",
    "    vector_store=\"azure_cognitive_search\",\n",
    "    embeddings_model = f\"azure_open_ai://deployment/{embedding_model_deployment}/model/text-embedding-ada-002\",\n",
    "    data_source_url=\"https://product_info.com\",\n",
    "    index_input_config=LocalSource(input_data=\"../../data/3-product-info\"),\n",
    "    acs_config=ACSOutputConfig(\n",
    "        acs_index_name=\"product-info-index-test1\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# register the index so that it shows up in the project\n",
    "client.mlindexes.create_or_update(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement co-pilot logic using Semantic Kernel and the MLIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cognitive_search import AzureCognitiveSearchMemoryStore\n",
    "from semantic_kernel.connectors.memory.azure_cognitive_search import utils as acs_utils\n",
    "\n",
    "# Create a connection to Azure Cognitive Search using the default ACS connection\n",
    "memory_store = AzureCognitiveSearchMemoryStore(\n",
    "    vector_size=1536,\n",
    "    search_endpoint=default_acs_connection.target,\n",
    "    admin_key=default_acs_connection.credentials.key,\n",
    "    custom_schema={\n",
    "        acs_utils.SEARCH_FIELD_ID_KEY: \"id\",\n",
    "        acs_utils.SEARCH_FIELD_TEXT_KEY: \"content\",\n",
    "        acs_utils.SEARCH_FIELD_EMBEDDING_KEY: \"content_vector_open_ai\",\n",
    "        acs_utils.SEARCH_FIELD_SRC_KEY: \"sourcepage\",\n",
    "        acs_utils.SEARCH_FIELD_DESC_KEY: \"content\",\n",
    "        acs_utils.SEARCH_FIELD_METADATA_KEY: \"meta_json_string\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a QnA function that retrieves data and uses it as context to the LLM\n",
    "def qna(question, temperature=0.0, number_of_docs=10):\n",
    "    import semantic_kernel as sk\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "    from semantic_kernel.planning import StepwisePlanner\n",
    "    from semantic_kernel.planning.stepwise_planner.stepwise_planner_config import StepwisePlannerConfig\n",
    "    from plugins.customer_support_plugin.customer_support import CustomerSupport\n",
    "\n",
    "    import os\n",
    "\n",
    "    # Hack to support async functions\n",
    "    import asyncio\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Initialize the kernel\n",
    "    kernel = sk.Kernel()\n",
    "    kernel.add_chat_service(\n",
    "        \"chat_completion\",\n",
    "        AzureChatCompletion(\n",
    "            chat_model_deployment,\n",
    "            os.getenv(\"OPENAI_API_BASE\"),\n",
    "            os.getenv(\"OPENAI_API_KEY\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add the customer support plugin to the kernel\n",
    "    kernel.import_skill(CustomerSupport(\n",
    "        memory_store = memory_store,\n",
    "        number_of_docs = number_of_docs,\n",
    "        embedding_model_deployment = embedding_model_deployment,\n",
    "        chat_model_deployment=chat_model_deployment,\n",
    "        temperature=temperature\n",
    "    ), skill_name=\"CustomerSupport\")\n",
    "\n",
    "    # Create and run plan based on the customer ask\n",
    "    planner = StepwisePlanner(kernel, config=StepwisePlannerConfig(max_iterations=5))\n",
    "    plan = planner.create_plan(question)\n",
    "    result = asyncio.run(kernel.run_async(plan))\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": result.result\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The waterproof rating for the tent is 2000mm.\n"
     ]
    }
   ],
   "source": [
    "result = qna(\"What's the waterproof rating for the tent I just ordered?\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate LLM Response on Larger Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Loading data\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "path = os.path.join(os.getcwd() + \"/data.jsonl\")\n",
    "data = load_jsonl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n",
      "{'artifacts': {'gpt_coherence': ['3',\n",
      "                                 '3',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '1',\n",
      "                                 '5',\n",
      "                                 '3',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '3',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '1'],\n",
      "               'gpt_fluency': ['3',\n",
      "                               '3',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '5',\n",
      "                               '1'],\n",
      "               'gpt_groundedness': ['1',\n",
      "                                    '1',\n",
      "                                    '1',\n",
      "                                    '1',\n",
      "                                    '5',\n",
      "                                    '5',\n",
      "                                    '5',\n",
      "                                    '1',\n",
      "                                    '5',\n",
      "                                    '1',\n",
      "                                    '1',\n",
      "                                    '1',\n",
      "                                    '1'],\n",
      "               'gpt_relevance': ['5',\n",
      "                                 '3',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '3',\n",
      "                                 '5',\n",
      "                                 '5',\n",
      "                                 '1'],\n",
      "               'gpt_similarity': ['3',\n",
      "                                  '3',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '1',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '1']},\n",
      " 'metrics': {'exact_match': 0.0,\n",
      "             'f1_score': 0.41946997810793607,\n",
      "             'mean_bertscore_f1': 0.3653343729674816,\n",
      "             'mean_bertscore_precision': 0.25083251841939413,\n",
      "             'mean_bertscore_recall': 0.5164986585195248}}\n",
      "Open in AI Studio: https://ml.azure.com/projectEvaluation?flight=AiStudio,DeployChatWebapp,SkipAADRegistration/projectEvaluation&wsid=/subscriptions/597966d1-829f-417e-9950-8189061ec09c/resourceGroups/azureai_development/providers/Microsoft.MachineLearningServices/workspaces/dantaylo-bugbashcli\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.generative.evaluate import evaluate\n",
    "from pprint import pprint\n",
    "\n",
    "# Evaluate the default vs the improved system prompt to see if the improved prompt\n",
    "# performs consistently better across a larger set of inputs\n",
    "result = evaluate(\n",
    "    evaluation_name=\"baseline-evaluation\",\n",
    "    asset=qna,# model_uri:\n",
    "    data=data,\n",
    "    task_type=\"qa\",\n",
    "    prediction_data=\"answer\",\n",
    "    truth_data=\"truth\", # Optional\n",
    "    metrics_config={\n",
    "        \"openai_params\": {\n",
    "            \"api_version\": \"2023-05-15\",\n",
    "            \"api_base\": os.getenv(\"OPENAI_API_BASE\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"deployment_id\": chat_model_deployment\n",
    "        },\n",
    "        \"questions\": \"question\",\n",
    "        \"contexts\": \"context\",\n",
    "    },\n",
    "    tracking_uri=client.tracking_uri,\n",
    ")\n",
    "pprint(result)\n",
    "\n",
    "# Print a link to open the evalautions page in AI Studio\n",
    "print(f\"Open in AI Studio: https://ml.azure.com/projectEvaluation?flight=AiStudio,DeployChatWebapp,SkipAADRegistration/projectEvaluation&wsid=/subscriptions/{client.subscription_id}/resourceGroups/{client.resource_group_name}/providers/Microsoft.MachineLearningServices/workspaces/{client.project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate copilot performance across different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n",
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n",
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n",
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying azureml.metrics.text.qa._similarity_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n",
      "test data is not a file but loaded data\n",
      "Error logging data as dataset, continuing without it\n",
      "[{'artifacts': {'gpt_coherence': ['5',\n",
      "                                  '3',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '1',\n",
      "                                  '5',\n",
      "                                  '3',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '3',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '1'],\n",
      "                'gpt_fluency': ['5',\n",
      "                                '3',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '3',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '5',\n",
      "                                '1'],\n",
      "                'gpt_groundedness': ['5',\n",
      "                                     '1',\n",
      "                                     '1',\n",
      "                                     '1',\n",
      "                                     '1',\n",
      "                                     '5',\n",
      "                                     '5',\n",
      "                                     '5',\n",
      "                                     '5',\n",
      "                                     '1',\n",
      "                                     '1',\n",
      "                                     '5',\n",
      "                                     '1'],\n",
      "                'gpt_relevance': ['5',\n",
      "                                  '1',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '3',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '3',\n",
      "                                  '5',\n",
      "                                  '5',\n",
      "                                  '1'],\n",
      "                'gpt_similarity': ['5',\n",
      "                                   '1',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '1',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '5',\n",
      "                                   '1']},\n",
      "  'metrics': {'exact_match': 0.0,\n",
      "              'f1_score': 0.44378049510720124,\n",
      "              'mean_bertscore_f1': 0.3843197389864005,\n",
      "              'mean_bertscore_precision': 0.2723219062273319,\n",
      "              'mean_bertscore_recall': 0.5311282953390708}}]\n",
      "Open in AI Studio: https://ml.azure.com/projectEvaluation?flight=AiStudio,DeployChatWebapp,SkipAADRegistration/projectEvaluation&wsid=/subscriptions/597966d1-829f-417e-9950-8189061ec09c/resourceGroups/azureai_development/providers/Microsoft.MachineLearningServices/workspaces/dantaylo-bugbashcli\n"
     ]
    }
   ],
   "source": [
    "# Sweep over different values of temperature and number_of_docs to find the best value\n",
    "# Evaluation results will be logged to project by setting tracking_uri\n",
    "result = evaluate( \n",
    "    evaluation_name=\"qna-params-eval\",\n",
    "    asset=qna,\n",
    "    data=data,\n",
    "    task_type=\"qa\",\n",
    "    prediction_data=\"answer\",\n",
    "    truth_data=\"truth\", # Optional\n",
    "    metrics_config={\n",
    "        \"openai_params\": {\n",
    "            \"api_version\": \"2023-05-15\",\n",
    "            \"api_base\": os.getenv(\"OPENAI_API_BASE\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"deployment_id\": chat_model_deployment\n",
    "        },\n",
    "        \"questions\": \"question\",\n",
    "        \"contexts\": \"context\",\n",
    "    },\n",
    "    tracking_uri=client.tracking_uri,\n",
    "    params={\n",
    "        \"temperature\": [0.0, 0,1],\n",
    "        \"number_of_docs\": [5, 10]\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(result)\n",
    "\n",
    "# Print a link to open the evalautions page in AI Studio\n",
    "print(f\"Open in AI Studio: https://ml.azure.com/projectEvaluation?flight=AiStudio,DeployChatWebapp,SkipAADRegistration/projectEvaluation&wsid=/subscriptions/{client.subscription_id}/resourceGroups/{client.resource_group_name}/providers/Microsoft.MachineLearningServices/workspaces/{client.project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Semantic Kernel QA Function to MIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MLIndex files so they can be packaged with deployment code\n",
    "client.mlindexes.download(name=\"product-info-cog-search-index\", download_path=\"./qna_simple/mlindex\", label=\"latest\")\n",
    "\n",
    "# set the deployment name to be used, the url needs to be globally unique so include project name\n",
    "deployment_name = f\"{client.project_name}-sk-copilot\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System-assigned identity already has access to project. Skipping granting it access to project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint dantaylo-bugbashcli-sk-copilot exists\n",
      "Uploading mlflow_model (0.02 MBs): 100%|██████████| 16643/16643 [00:00<00:00, 26566.58it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
      "Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.generative.entities.deployment import Deployment\n",
    "from azure.ai.generative.entities.models import LocalModel\n",
    "\n",
    "deployment = Deployment(\n",
    "    name=deployment_name,\n",
    "    model=LocalModel(\n",
    "        path=\"./qna_simple\",\n",
    "        conda_file=\"conda.yaml\",\n",
    "        loader_module=\"model_loader.py\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "deployment = client.deployments.create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"question\": \"Which tent has the highest rainfly waterproof rating?\", \"answer\": \"Sorry, I can only answer questions related to outdoor/camping gear and clothing. How can I assist you with that?\\\"\"}]\n"
     ]
    }
   ],
   "source": [
    "response = client.deployments.invoke(deployment_name, \"./request_file_qna_simple.json\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
